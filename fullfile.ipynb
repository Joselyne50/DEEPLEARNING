{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Joselyne50/DEEPLEARNING/blob/ASSIGNMENT/fullfile.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#frameworks and packages"
      ],
      "metadata": {
        "id": "cFv1ZgY33dkJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "UCPc6Qy2lsnP",
        "outputId": "79a1a985-2968-4fe5-a2a4-abd580423245"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "B5izHLIkl0MB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "# import torch.nn.functional as F\n",
        "# import numpy as np\n",
        "# from sklearn.model_selection import StratifiedShuffleSplit\n",
        "# from torch.utils.data.sampler import SubsetRandomSampler\n",
        "# from torchvision import datasets, transforms\n",
        "# import matplotlib\n",
        "# matplotlib.use('Agg')\n",
        "# import matplotlib.pyplot as plt\n",
        "# import os\n"
      ],
      "metadata": {
        "id": "kwI6rW0N3cpb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#run.sh"
      ],
      "metadata": {
        "id": "43k7wpu34m4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#export CUBLAS_WORKSPACE_CONFIG=:16:8\n",
        "\n",
        "!python /content/drive/MyDrive/Deeplearningassign1/m.py \\\n",
        "--dataset_dir ./mydata2/ \\\n",
        "--batch_size 128 \\\n",
        "--epochs 300 \\\n",
        "--lr 0.05 --wd 0.0005 \\\n",
        "--lr_scheduler \\\n",
        "--mixup \\\n",
        "--seed 0 \\\n",
        "--fig_name lr=0.05-lr_sche-wd=0.0005-mixup.png \\\n",
        "--test\n"
      ],
      "metadata": {
        "id": "CH2_HF5X4oko",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "930e09e3-dd0c-4ccb-ee53-76b256101b1a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Mean: [0.507108747959137, 0.48638272285461426, 0.4406910240650177], Std: [0.2675017714500427, 0.2566560208797455, 0.2763121724128723]\n",
            "ARGS PASSED:  Namespace(dataset_dir='./mydata2/', batch_size=128, epochs=300, lr=0.05, wd=0.0005, fig_name='lr=0.05-lr_sche-wd=0.0005-mixup.png', lr_scheduler=True, mixup=True, alpha=1.0, test=True, save_images=False, seed=0)\n",
            "DIR ----> DIAGRAM not created ---->[Errno 17] File exists: '/content/diagram'\n",
            "DATASET DIR:  mydata2\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "MobileNet(\n",
            "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layers): Sequential(\n",
            "    (0): Block(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): Block(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (2): Block(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (3): Block(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=128, bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (4): Block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (5): Block(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=256, bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (6): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (7): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (8): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (9): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (10): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (11): Block(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=512, bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (12): Block(\n",
            "      (conv1): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "      (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=1024, out_features=100, bias=True)\n",
            ")\n",
            "/usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:814: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
            "Epoch 1/300.. Learning rate: 0.0500.. Train loss: 4.3882.. Train acc: 0.0410.. Val loss: 4.1489.. Val acc: 0.0787\n",
            "Epoch 2/300.. Learning rate: 0.0500.. Train loss: 4.1064.. Train acc: 0.0812.. Val loss: 3.7150.. Val acc: 0.1291\n",
            "Epoch 3/300.. Learning rate: 0.0500.. Train loss: 3.9735.. Train acc: 0.1068.. Val loss: 3.4824.. Val acc: 0.1647\n",
            "Epoch 4/300.. Learning rate: 0.0500.. Train loss: 3.8793.. Train acc: 0.1262.. Val loss: 3.4314.. Val acc: 0.1724\n",
            "Epoch 5/300.. Learning rate: 0.0500.. Train loss: 3.7676.. Train acc: 0.1449.. Val loss: 3.2604.. Val acc: 0.2126\n",
            "Epoch 6/300.. Learning rate: 0.0500.. Train loss: 3.6999.. Train acc: 0.1622.. Val loss: 3.5661.. Val acc: 0.1789\n",
            "Epoch 7/300.. Learning rate: 0.0499.. Train loss: 3.5719.. Train acc: 0.1857.. Val loss: 3.1060.. Val acc: 0.2405\n",
            "Epoch 8/300.. Learning rate: 0.0499.. Train loss: 3.5073.. Train acc: 0.2025.. Val loss: 2.9317.. Val acc: 0.2644\n",
            "Epoch 9/300.. Learning rate: 0.0499.. Train loss: 3.4691.. Train acc: 0.2106.. Val loss: 2.7401.. Val acc: 0.3176\n",
            "Epoch 10/300.. Learning rate: 0.0499.. Train loss: 3.3976.. Train acc: 0.2279.. Val loss: 2.8742.. Val acc: 0.2841\n",
            "Epoch 11/300.. Learning rate: 0.0498.. Train loss: 3.2917.. Train acc: 0.2480.. Val loss: 2.6707.. Val acc: 0.3204\n",
            "Epoch 12/300.. Learning rate: 0.0498.. Train loss: 3.2529.. Train acc: 0.2606.. Val loss: 2.5389.. Val acc: 0.3580\n",
            "Epoch 13/300.. Learning rate: 0.0498.. Train loss: 3.2790.. Train acc: 0.2579.. Val loss: 2.4027.. Val acc: 0.3868\n",
            "Epoch 14/300.. Learning rate: 0.0497.. Train loss: 3.1558.. Train acc: 0.2839.. Val loss: 2.3820.. Val acc: 0.3984\n",
            "Epoch 15/300.. Learning rate: 0.0497.. Train loss: 3.1058.. Train acc: 0.2943.. Val loss: 2.4311.. Val acc: 0.3820\n",
            "Epoch 16/300.. Learning rate: 0.0497.. Train loss: 3.0484.. Train acc: 0.3067.. Val loss: 2.3033.. Val acc: 0.4053\n",
            "Epoch 17/300.. Learning rate: 0.0496.. Train loss: 3.0581.. Train acc: 0.3062.. Val loss: 2.3905.. Val acc: 0.3923\n",
            "Epoch 18/300.. Learning rate: 0.0496.. Train loss: 3.1007.. Train acc: 0.3001.. Val loss: 2.2866.. Val acc: 0.4217\n",
            "Epoch 19/300.. Learning rate: 0.0495.. Train loss: 3.0141.. Train acc: 0.3188.. Val loss: 2.2752.. Val acc: 0.4219\n",
            "Epoch 20/300.. Learning rate: 0.0495.. Train loss: 3.0057.. Train acc: 0.3236.. Val loss: 2.2173.. Val acc: 0.4336\n",
            "Epoch 21/300.. Learning rate: 0.0494.. Train loss: 3.0150.. Train acc: 0.3206.. Val loss: 2.1887.. Val acc: 0.4396\n",
            "Epoch 22/300.. Learning rate: 0.0493.. Train loss: 2.9516.. Train acc: 0.3330.. Val loss: 2.2914.. Val acc: 0.4211\n",
            "Epoch 23/300.. Learning rate: 0.0493.. Train loss: 2.9243.. Train acc: 0.3408.. Val loss: 2.1711.. Val acc: 0.4491\n",
            "Epoch 24/300.. Learning rate: 0.0492.. Train loss: 2.9786.. Train acc: 0.3312.. Val loss: 2.1578.. Val acc: 0.4575\n",
            "Epoch 25/300.. Learning rate: 0.0492.. Train loss: 2.9378.. Train acc: 0.3393.. Val loss: 2.2745.. Val acc: 0.4348\n",
            "Epoch 26/300.. Learning rate: 0.0491.. Train loss: 2.9552.. Train acc: 0.3377.. Val loss: 2.0734.. Val acc: 0.4679\n",
            "Epoch 27/300.. Learning rate: 0.0490.. Train loss: 2.9660.. Train acc: 0.3356.. Val loss: 2.1158.. Val acc: 0.4668\n",
            "Epoch 28/300.. Learning rate: 0.0489.. Train loss: 2.8823.. Train acc: 0.3522.. Val loss: 2.1152.. Val acc: 0.4650\n",
            "Epoch 29/300.. Learning rate: 0.0489.. Train loss: 2.8956.. Train acc: 0.3500.. Val loss: 2.2247.. Val acc: 0.4498\n",
            "Epoch 30/300.. Learning rate: 0.0488.. Train loss: 2.9493.. Train acc: 0.3420.. Val loss: 2.0082.. Val acc: 0.4714\n",
            "Epoch 31/300.. Learning rate: 0.0487.. Train loss: 2.8776.. Train acc: 0.3555.. Val loss: 1.9879.. Val acc: 0.4931\n",
            "Epoch 32/300.. Learning rate: 0.0486.. Train loss: 2.9157.. Train acc: 0.3483.. Val loss: 2.0204.. Val acc: 0.4833\n",
            "Epoch 33/300.. Learning rate: 0.0485.. Train loss: 2.8575.. Train acc: 0.3622.. Val loss: 2.2945.. Val acc: 0.4318\n",
            "Epoch 34/300.. Learning rate: 0.0484.. Train loss: 2.8847.. Train acc: 0.3532.. Val loss: 2.1600.. Val acc: 0.4559\n",
            "Epoch 35/300.. Learning rate: 0.0483.. Train loss: 2.8139.. Train acc: 0.3696.. Val loss: 2.1292.. Val acc: 0.4681\n",
            "Epoch 36/300.. Learning rate: 0.0482.. Train loss: 2.7997.. Train acc: 0.3727.. Val loss: 2.0585.. Val acc: 0.4843\n",
            "Epoch 37/300.. Learning rate: 0.0481.. Train loss: 2.8331.. Train acc: 0.3651.. Val loss: 2.1128.. Val acc: 0.4672\n",
            "Epoch 38/300.. Learning rate: 0.0480.. Train loss: 2.8325.. Train acc: 0.3706.. Val loss: 2.0101.. Val acc: 0.5063\n",
            "Epoch 39/300.. Learning rate: 0.0479.. Train loss: 2.8208.. Train acc: 0.3703.. Val loss: 2.0880.. Val acc: 0.4753\n",
            "Epoch 40/300.. Learning rate: 0.0478.. Train loss: 2.7767.. Train acc: 0.3807.. Val loss: 1.8836.. Val acc: 0.5043\n",
            "Epoch 41/300.. Learning rate: 0.0477.. Train loss: 2.8284.. Train acc: 0.3710.. Val loss: 1.9719.. Val acc: 0.4998\n",
            "Epoch 42/300.. Learning rate: 0.0476.. Train loss: 2.7823.. Train acc: 0.3801.. Val loss: 2.0241.. Val acc: 0.4967\n",
            "Epoch 43/300.. Learning rate: 0.0475.. Train loss: 2.8276.. Train acc: 0.3718.. Val loss: 1.9757.. Val acc: 0.4916\n",
            "Epoch 44/300.. Learning rate: 0.0474.. Train loss: 2.8552.. Train acc: 0.3647.. Val loss: 2.0625.. Val acc: 0.4800\n",
            "Epoch 45/300.. Learning rate: 0.0473.. Train loss: 2.8054.. Train acc: 0.3724.. Val loss: 2.1576.. Val acc: 0.4685\n",
            "Epoch 46/300.. Learning rate: 0.0472.. Train loss: 2.8059.. Train acc: 0.3786.. Val loss: 2.0926.. Val acc: 0.4789\n",
            "Epoch 47/300.. Learning rate: 0.0470.. Train loss: 2.8011.. Train acc: 0.3749.. Val loss: 1.9896.. Val acc: 0.5029\n",
            "Epoch 48/300.. Learning rate: 0.0469.. Train loss: 2.7279.. Train acc: 0.3959.. Val loss: 1.8668.. Val acc: 0.5249\n",
            "Epoch 49/300.. Learning rate: 0.0468.. Train loss: 2.7564.. Train acc: 0.3881.. Val loss: 1.9421.. Val acc: 0.5115\n",
            "Epoch 50/300.. Learning rate: 0.0467.. Train loss: 2.8462.. Train acc: 0.3672.. Val loss: 2.0287.. Val acc: 0.4923\n",
            "Epoch 51/300.. Learning rate: 0.0465.. Train loss: 2.7770.. Train acc: 0.3824.. Val loss: 2.1255.. Val acc: 0.4657\n",
            "Epoch 52/300.. Learning rate: 0.0464.. Train loss: 2.8162.. Train acc: 0.3750.. Val loss: 1.9954.. Val acc: 0.4949\n",
            "Epoch 53/300.. Learning rate: 0.0463.. Train loss: 2.7620.. Train acc: 0.3872.. Val loss: 1.9009.. Val acc: 0.5305\n",
            "Epoch 54/300.. Learning rate: 0.0461.. Train loss: 2.7547.. Train acc: 0.3899.. Val loss: 1.9269.. Val acc: 0.5060\n",
            "Epoch 55/300.. Learning rate: 0.0460.. Train loss: 2.7790.. Train acc: 0.3809.. Val loss: 1.9045.. Val acc: 0.5160\n",
            "Epoch 56/300.. Learning rate: 0.0458.. Train loss: 2.7723.. Train acc: 0.3846.. Val loss: 1.8741.. Val acc: 0.5181\n",
            "Epoch 57/300.. Learning rate: 0.0457.. Train loss: 2.7591.. Train acc: 0.3882.. Val loss: 1.8799.. Val acc: 0.5280\n",
            "Epoch 58/300.. Learning rate: 0.0455.. Train loss: 2.6981.. Train acc: 0.4032.. Val loss: 1.9949.. Val acc: 0.5061\n",
            "Epoch 59/300.. Learning rate: 0.0454.. Train loss: 2.7381.. Train acc: 0.3948.. Val loss: 2.0321.. Val acc: 0.4951\n",
            "Epoch 60/300.. Learning rate: 0.0452.. Train loss: 2.7383.. Train acc: 0.3962.. Val loss: 1.9694.. Val acc: 0.5135\n",
            "Epoch 61/300.. Learning rate: 0.0451.. Train loss: 2.7094.. Train acc: 0.3990.. Val loss: 2.0096.. Val acc: 0.4966\n",
            "Epoch 62/300.. Learning rate: 0.0449.. Train loss: 2.7524.. Train acc: 0.3924.. Val loss: 1.9729.. Val acc: 0.5030\n",
            "Epoch 63/300.. Learning rate: 0.0448.. Train loss: 2.6665.. Train acc: 0.4092.. Val loss: 1.9201.. Val acc: 0.5176\n",
            "Epoch 64/300.. Learning rate: 0.0446.. Train loss: 2.7080.. Train acc: 0.4009.. Val loss: 1.8741.. Val acc: 0.5237\n",
            "Epoch 65/300.. Learning rate: 0.0444.. Train loss: 2.7027.. Train acc: 0.4021.. Val loss: 1.9903.. Val acc: 0.5072\n",
            "Epoch 66/300.. Learning rate: 0.0443.. Train loss: 2.7000.. Train acc: 0.4065.. Val loss: 1.8385.. Val acc: 0.5279\n",
            "Epoch 67/300.. Learning rate: 0.0441.. Train loss: 2.7124.. Train acc: 0.3994.. Val loss: 1.8369.. Val acc: 0.5257\n",
            "Epoch 68/300.. Learning rate: 0.0439.. Train loss: 2.6718.. Train acc: 0.4088.. Val loss: 1.8489.. Val acc: 0.5314\n",
            "Epoch 69/300.. Learning rate: 0.0438.. Train loss: 2.7149.. Train acc: 0.3979.. Val loss: 1.8060.. Val acc: 0.5388\n",
            "Epoch 70/300.. Learning rate: 0.0436.. Train loss: 2.6731.. Train acc: 0.4098.. Val loss: 1.8039.. Val acc: 0.5361\n",
            "Epoch 71/300.. Learning rate: 0.0434.. Train loss: 2.6986.. Train acc: 0.4049.. Val loss: 1.9410.. Val acc: 0.5134\n",
            "Epoch 72/300.. Learning rate: 0.0432.. Train loss: 2.7115.. Train acc: 0.4035.. Val loss: 1.9239.. Val acc: 0.5225\n",
            "Epoch 73/300.. Learning rate: 0.0430.. Train loss: 2.7109.. Train acc: 0.4018.. Val loss: 1.8293.. Val acc: 0.5362\n",
            "Epoch 74/300.. Learning rate: 0.0429.. Train loss: 2.6863.. Train acc: 0.4062.. Val loss: 1.8154.. Val acc: 0.5364\n",
            "Epoch 75/300.. Learning rate: 0.0427.. Train loss: 2.6422.. Train acc: 0.4184.. Val loss: 1.8299.. Val acc: 0.5379\n",
            "Epoch 76/300.. Learning rate: 0.0425.. Train loss: 2.7157.. Train acc: 0.4025.. Val loss: 1.7898.. Val acc: 0.5492\n",
            "Epoch 77/300.. Learning rate: 0.0423.. Train loss: 2.6266.. Train acc: 0.4215.. Val loss: 1.8608.. Val acc: 0.5325\n",
            "Epoch 78/300.. Learning rate: 0.0421.. Train loss: 2.6958.. Train acc: 0.4072.. Val loss: 1.8592.. Val acc: 0.5315\n",
            "Epoch 79/300.. Learning rate: 0.0419.. Train loss: 2.6686.. Train acc: 0.4102.. Val loss: 1.8193.. Val acc: 0.5443\n",
            "Epoch 80/300.. Learning rate: 0.0417.. Train loss: 2.6207.. Train acc: 0.4231.. Val loss: 1.7613.. Val acc: 0.5529\n",
            "Epoch 81/300.. Learning rate: 0.0415.. Train loss: 2.6357.. Train acc: 0.4212.. Val loss: 1.9332.. Val acc: 0.5223\n",
            "Epoch 82/300.. Learning rate: 0.0413.. Train loss: 2.5929.. Train acc: 0.4295.. Val loss: 1.9040.. Val acc: 0.5325\n",
            "Epoch 83/300.. Learning rate: 0.0411.. Train loss: 2.6649.. Train acc: 0.4133.. Val loss: 1.7001.. Val acc: 0.5662\n",
            "Epoch 84/300.. Learning rate: 0.0409.. Train loss: 2.6631.. Train acc: 0.4141.. Val loss: 1.7825.. Val acc: 0.5491\n",
            "Epoch 85/300.. Learning rate: 0.0407.. Train loss: 2.6304.. Train acc: 0.4198.. Val loss: 1.8904.. Val acc: 0.5197\n",
            "Epoch 86/300.. Learning rate: 0.0405.. Train loss: 2.6557.. Train acc: 0.4159.. Val loss: 1.8981.. Val acc: 0.5309\n",
            "Epoch 87/300.. Learning rate: 0.0403.. Train loss: 2.6341.. Train acc: 0.4159.. Val loss: 1.7255.. Val acc: 0.5627\n",
            "Epoch 88/300.. Learning rate: 0.0401.. Train loss: 2.6139.. Train acc: 0.4257.. Val loss: 1.9223.. Val acc: 0.5266\n",
            "Epoch 89/300.. Learning rate: 0.0399.. Train loss: 2.5957.. Train acc: 0.4299.. Val loss: 1.8261.. Val acc: 0.5411\n",
            "Epoch 90/300.. Learning rate: 0.0397.. Train loss: 2.6565.. Train acc: 0.4151.. Val loss: 1.7878.. Val acc: 0.5453\n",
            "Epoch 91/300.. Learning rate: 0.0395.. Train loss: 2.6197.. Train acc: 0.4252.. Val loss: 1.7832.. Val acc: 0.5550\n",
            "Epoch 92/300.. Learning rate: 0.0393.. Train loss: 2.5811.. Train acc: 0.4337.. Val loss: 1.9597.. Val acc: 0.5126\n",
            "Epoch 93/300.. Learning rate: 0.0391.. Train loss: 2.6368.. Train acc: 0.4220.. Val loss: 1.8843.. Val acc: 0.5267\n",
            "Epoch 94/300.. Learning rate: 0.0388.. Train loss: 2.5880.. Train acc: 0.4322.. Val loss: 1.7738.. Val acc: 0.5469\n",
            "Epoch 95/300.. Learning rate: 0.0386.. Train loss: 2.6227.. Train acc: 0.4210.. Val loss: 1.9336.. Val acc: 0.5095\n",
            "Epoch 96/300.. Learning rate: 0.0384.. Train loss: 2.6474.. Train acc: 0.4180.. Val loss: 1.9108.. Val acc: 0.5295\n",
            "Epoch 97/300.. Learning rate: 0.0382.. Train loss: 2.5914.. Train acc: 0.4269.. Val loss: 1.7994.. Val acc: 0.5484\n",
            "Epoch 98/300.. Learning rate: 0.0380.. Train loss: 2.5671.. Train acc: 0.4347.. Val loss: 1.8565.. Val acc: 0.5343\n",
            "Epoch 99/300.. Learning rate: 0.0377.. Train loss: 2.6326.. Train acc: 0.4224.. Val loss: 1.8365.. Val acc: 0.5474\n",
            "Epoch 100/300.. Learning rate: 0.0375.. Train loss: 2.4721.. Train acc: 0.4580.. Val loss: 1.7099.. Val acc: 0.5714\n",
            "Epoch 101/300.. Learning rate: 0.0373.. Train loss: 2.5526.. Train acc: 0.4416.. Val loss: 1.7824.. Val acc: 0.5509\n",
            "Epoch 102/300.. Learning rate: 0.0370.. Train loss: 2.5636.. Train acc: 0.4355.. Val loss: 1.7849.. Val acc: 0.5527\n",
            "Epoch 103/300.. Learning rate: 0.0368.. Train loss: 2.5895.. Train acc: 0.4337.. Val loss: 1.6445.. Val acc: 0.5757\n",
            "Epoch 104/300.. Learning rate: 0.0366.. Train loss: 2.6320.. Train acc: 0.4264.. Val loss: 1.7353.. Val acc: 0.5695\n",
            "Epoch 105/300.. Learning rate: 0.0364.. Train loss: 2.5544.. Train acc: 0.4410.. Val loss: 1.8127.. Val acc: 0.5445\n",
            "Epoch 106/300.. Learning rate: 0.0361.. Train loss: 2.5163.. Train acc: 0.4504.. Val loss: 1.7412.. Val acc: 0.5668\n",
            "Epoch 107/300.. Learning rate: 0.0359.. Train loss: 2.5510.. Train acc: 0.4393.. Val loss: 1.7524.. Val acc: 0.5598\n",
            "Epoch 108/300.. Learning rate: 0.0356.. Train loss: 2.6000.. Train acc: 0.4284.. Val loss: 1.8040.. Val acc: 0.5446\n",
            "Epoch 109/300.. Learning rate: 0.0354.. Train loss: 2.5732.. Train acc: 0.4396.. Val loss: 1.7965.. Val acc: 0.5475\n",
            "Epoch 110/300.. Learning rate: 0.0352.. Train loss: 2.5496.. Train acc: 0.4418.. Val loss: 1.7365.. Val acc: 0.5664\n",
            "Epoch 111/300.. Learning rate: 0.0349.. Train loss: 2.6656.. Train acc: 0.4146.. Val loss: 1.8114.. Val acc: 0.5530\n",
            "Epoch 112/300.. Learning rate: 0.0347.. Train loss: 2.5959.. Train acc: 0.4323.. Val loss: 1.8213.. Val acc: 0.5509\n",
            "Epoch 113/300.. Learning rate: 0.0344.. Train loss: 2.5772.. Train acc: 0.4348.. Val loss: 1.7297.. Val acc: 0.5626\n",
            "Epoch 114/300.. Learning rate: 0.0342.. Train loss: 2.5804.. Train acc: 0.4335.. Val loss: 1.7571.. Val acc: 0.5549\n",
            "Epoch 115/300.. Learning rate: 0.0340.. Train loss: 2.5789.. Train acc: 0.4372.. Val loss: 1.7523.. Val acc: 0.5708\n",
            "Epoch 116/300.. Learning rate: 0.0337.. Train loss: 2.4867.. Train acc: 0.4512.. Val loss: 1.7006.. Val acc: 0.5784\n",
            "Epoch 117/300.. Learning rate: 0.0335.. Train loss: 2.4893.. Train acc: 0.4564.. Val loss: 1.6948.. Val acc: 0.5807\n",
            "Epoch 118/300.. Learning rate: 0.0332.. Train loss: 2.4902.. Train acc: 0.4547.. Val loss: 1.7342.. Val acc: 0.5781\n",
            "Epoch 119/300.. Learning rate: 0.0330.. Train loss: 2.5256.. Train acc: 0.4467.. Val loss: 1.6497.. Val acc: 0.5806\n",
            "Epoch 120/300.. Learning rate: 0.0327.. Train loss: 2.5146.. Train acc: 0.4491.. Val loss: 1.6837.. Val acc: 0.5746\n",
            "Epoch 121/300.. Learning rate: 0.0325.. Train loss: 2.5606.. Train acc: 0.4406.. Val loss: 1.6966.. Val acc: 0.5791\n",
            "Epoch 122/300.. Learning rate: 0.0322.. Train loss: 2.5356.. Train acc: 0.4469.. Val loss: 1.7033.. Val acc: 0.5798\n",
            "Epoch 123/300.. Learning rate: 0.0320.. Train loss: 2.5787.. Train acc: 0.4355.. Val loss: 1.6819.. Val acc: 0.5821\n",
            "Epoch 124/300.. Learning rate: 0.0317.. Train loss: 2.5872.. Train acc: 0.4359.. Val loss: 1.7890.. Val acc: 0.5654\n",
            "Epoch 125/300.. Learning rate: 0.0315.. Train loss: 2.5208.. Train acc: 0.4537.. Val loss: 1.7543.. Val acc: 0.5726\n",
            "Epoch 126/300.. Learning rate: 0.0312.. Train loss: 2.5026.. Train acc: 0.4517.. Val loss: 1.6536.. Val acc: 0.5817\n",
            "Epoch 127/300.. Learning rate: 0.0310.. Train loss: 2.4142.. Train acc: 0.4724.. Val loss: 1.7527.. Val acc: 0.5685\n",
            "Epoch 128/300.. Learning rate: 0.0307.. Train loss: 2.4308.. Train acc: 0.4685.. Val loss: 1.6410.. Val acc: 0.5831\n",
            "Epoch 129/300.. Learning rate: 0.0305.. Train loss: 2.5173.. Train acc: 0.4506.. Val loss: 1.8197.. Val acc: 0.5525\n",
            "Epoch 130/300.. Learning rate: 0.0302.. Train loss: 2.4989.. Train acc: 0.4582.. Val loss: 1.7032.. Val acc: 0.5797\n",
            "Epoch 131/300.. Learning rate: 0.0299.. Train loss: 2.5035.. Train acc: 0.4561.. Val loss: 1.6920.. Val acc: 0.5781\n",
            "Epoch 132/300.. Learning rate: 0.0297.. Train loss: 2.5116.. Train acc: 0.4519.. Val loss: 1.8422.. Val acc: 0.5486\n",
            "Epoch 133/300.. Learning rate: 0.0294.. Train loss: 2.4469.. Train acc: 0.4698.. Val loss: 1.6159.. Val acc: 0.5939\n",
            "Epoch 134/300.. Learning rate: 0.0292.. Train loss: 2.4499.. Train acc: 0.4691.. Val loss: 1.6339.. Val acc: 0.5933\n",
            "Epoch 135/300.. Learning rate: 0.0289.. Train loss: 2.3544.. Train acc: 0.4868.. Val loss: 1.7437.. Val acc: 0.5690\n",
            "Epoch 136/300.. Learning rate: 0.0287.. Train loss: 2.4357.. Train acc: 0.4711.. Val loss: 1.6761.. Val acc: 0.5759\n",
            "Epoch 137/300.. Learning rate: 0.0284.. Train loss: 2.4194.. Train acc: 0.4747.. Val loss: 1.5906.. Val acc: 0.5921\n",
            "Epoch 138/300.. Learning rate: 0.0281.. Train loss: 2.5306.. Train acc: 0.4517.. Val loss: 1.9038.. Val acc: 0.5352\n",
            "Epoch 139/300.. Learning rate: 0.0279.. Train loss: 2.4827.. Train acc: 0.4605.. Val loss: 1.7308.. Val acc: 0.5718\n",
            "Epoch 140/300.. Learning rate: 0.0276.. Train loss: 2.4640.. Train acc: 0.4656.. Val loss: 1.6367.. Val acc: 0.5978\n",
            "Epoch 141/300.. Learning rate: 0.0274.. Train loss: 2.4731.. Train acc: 0.4632.. Val loss: 1.6140.. Val acc: 0.5931\n",
            "Epoch 142/300.. Learning rate: 0.0271.. Train loss: 2.4463.. Train acc: 0.4706.. Val loss: 1.5913.. Val acc: 0.5981\n",
            "Epoch 143/300.. Learning rate: 0.0268.. Train loss: 2.4589.. Train acc: 0.4662.. Val loss: 1.6820.. Val acc: 0.5794\n",
            "Epoch 144/300.. Learning rate: 0.0266.. Train loss: 2.3094.. Train acc: 0.5025.. Val loss: 1.6887.. Val acc: 0.5772\n",
            "Epoch 145/300.. Learning rate: 0.0263.. Train loss: 2.3891.. Train acc: 0.4878.. Val loss: 1.6424.. Val acc: 0.5851\n",
            "Epoch 146/300.. Learning rate: 0.0260.. Train loss: 2.3926.. Train acc: 0.4846.. Val loss: 1.5741.. Val acc: 0.6046\n",
            "Epoch 147/300.. Learning rate: 0.0258.. Train loss: 2.4629.. Train acc: 0.4660.. Val loss: 1.7101.. Val acc: 0.5799\n",
            "Epoch 148/300.. Learning rate: 0.0255.. Train loss: 2.4594.. Train acc: 0.4710.. Val loss: 1.6667.. Val acc: 0.5825\n",
            "Epoch 149/300.. Learning rate: 0.0253.. Train loss: 2.4203.. Train acc: 0.4797.. Val loss: 1.6025.. Val acc: 0.6007\n",
            "Epoch 150/300.. Learning rate: 0.0250.. Train loss: 2.3976.. Train acc: 0.4847.. Val loss: 1.6253.. Val acc: 0.5961\n",
            "Epoch 151/300.. Learning rate: 0.0247.. Train loss: 2.4095.. Train acc: 0.4775.. Val loss: 1.5958.. Val acc: 0.6042\n",
            "Epoch 152/300.. Learning rate: 0.0245.. Train loss: 2.4898.. Train acc: 0.4626.. Val loss: 1.5438.. Val acc: 0.6083\n",
            "Epoch 153/300.. Learning rate: 0.0242.. Train loss: 2.3965.. Train acc: 0.4829.. Val loss: 1.6405.. Val acc: 0.5976\n",
            "Epoch 154/300.. Learning rate: 0.0240.. Train loss: 2.4086.. Train acc: 0.4781.. Val loss: 1.6429.. Val acc: 0.5944\n",
            "Epoch 155/300.. Learning rate: 0.0237.. Train loss: 2.3418.. Train acc: 0.4966.. Val loss: 1.5679.. Val acc: 0.6072\n",
            "Epoch 156/300.. Learning rate: 0.0234.. Train loss: 2.4107.. Train acc: 0.4821.. Val loss: 1.6344.. Val acc: 0.6015\n",
            "Epoch 157/300.. Learning rate: 0.0232.. Train loss: 2.3609.. Train acc: 0.4951.. Val loss: 1.5767.. Val acc: 0.6072\n",
            "Epoch 158/300.. Learning rate: 0.0229.. Train loss: 2.3775.. Train acc: 0.4878.. Val loss: 1.6256.. Val acc: 0.5956\n",
            "Epoch 159/300.. Learning rate: 0.0227.. Train loss: 2.4167.. Train acc: 0.4814.. Val loss: 1.6336.. Val acc: 0.5896\n",
            "Epoch 160/300.. Learning rate: 0.0224.. Train loss: 2.3454.. Train acc: 0.4941.. Val loss: 1.5875.. Val acc: 0.6074\n",
            "Epoch 161/300.. Learning rate: 0.0221.. Train loss: 2.3420.. Train acc: 0.4982.. Val loss: 1.6169.. Val acc: 0.5995\n",
            "Epoch 162/300.. Learning rate: 0.0219.. Train loss: 2.3693.. Train acc: 0.4900.. Val loss: 1.5474.. Val acc: 0.6192\n",
            "Epoch 163/300.. Learning rate: 0.0216.. Train loss: 2.4236.. Train acc: 0.4808.. Val loss: 1.6040.. Val acc: 0.6091\n",
            "Epoch 164/300.. Learning rate: 0.0214.. Train loss: 2.3907.. Train acc: 0.4880.. Val loss: 1.5975.. Val acc: 0.6099\n",
            "Epoch 165/300.. Learning rate: 0.0211.. Train loss: 2.3461.. Train acc: 0.4988.. Val loss: 1.5808.. Val acc: 0.6109\n",
            "Epoch 166/300.. Learning rate: 0.0208.. Train loss: 2.3000.. Train acc: 0.5087.. Val loss: 1.5932.. Val acc: 0.5968\n",
            "Epoch 167/300.. Learning rate: 0.0206.. Train loss: 2.3159.. Train acc: 0.5014.. Val loss: 1.5887.. Val acc: 0.6085\n",
            "Epoch 168/300.. Learning rate: 0.0203.. Train loss: 2.3027.. Train acc: 0.5093.. Val loss: 1.6169.. Val acc: 0.5961\n",
            "Epoch 169/300.. Learning rate: 0.0201.. Train loss: 2.3000.. Train acc: 0.5055.. Val loss: 1.5522.. Val acc: 0.6072\n",
            "Epoch 170/300.. Learning rate: 0.0198.. Train loss: 2.2921.. Train acc: 0.5131.. Val loss: 1.5226.. Val acc: 0.6214\n",
            "Epoch 171/300.. Learning rate: 0.0195.. Train loss: 2.3010.. Train acc: 0.5094.. Val loss: 1.5557.. Val acc: 0.6254\n",
            "Epoch 172/300.. Learning rate: 0.0193.. Train loss: 2.3344.. Train acc: 0.5020.. Val loss: 1.5834.. Val acc: 0.6118\n",
            "Epoch 173/300.. Learning rate: 0.0190.. Train loss: 2.2725.. Train acc: 0.5169.. Val loss: 1.5454.. Val acc: 0.6193\n",
            "Epoch 174/300.. Learning rate: 0.0188.. Train loss: 2.3165.. Train acc: 0.5052.. Val loss: 1.5608.. Val acc: 0.6065\n",
            "Epoch 175/300.. Learning rate: 0.0185.. Train loss: 2.2853.. Train acc: 0.5152.. Val loss: 1.6309.. Val acc: 0.5925\n",
            "Epoch 176/300.. Learning rate: 0.0183.. Train loss: 2.3119.. Train acc: 0.5059.. Val loss: 1.6153.. Val acc: 0.6043\n",
            "Epoch 177/300.. Learning rate: 0.0180.. Train loss: 2.2809.. Train acc: 0.5154.. Val loss: 1.6399.. Val acc: 0.5999\n",
            "Epoch 178/300.. Learning rate: 0.0178.. Train loss: 2.2707.. Train acc: 0.5189.. Val loss: 1.5282.. Val acc: 0.6232\n",
            "Epoch 179/300.. Learning rate: 0.0175.. Train loss: 2.3085.. Train acc: 0.5102.. Val loss: 1.4900.. Val acc: 0.6322\n",
            "Epoch 180/300.. Learning rate: 0.0173.. Train loss: 2.2674.. Train acc: 0.5201.. Val loss: 1.5008.. Val acc: 0.6388\n",
            "Epoch 181/300.. Learning rate: 0.0170.. Train loss: 2.2026.. Train acc: 0.5350.. Val loss: 1.4298.. Val acc: 0.6414\n",
            "Epoch 182/300.. Learning rate: 0.0168.. Train loss: 2.2354.. Train acc: 0.5273.. Val loss: 1.5240.. Val acc: 0.6189\n",
            "Epoch 183/300.. Learning rate: 0.0165.. Train loss: 2.2924.. Train acc: 0.5163.. Val loss: 1.6483.. Val acc: 0.6073\n",
            "Epoch 184/300.. Learning rate: 0.0163.. Train loss: 2.2401.. Train acc: 0.5296.. Val loss: 1.4905.. Val acc: 0.6361\n",
            "Epoch 185/300.. Learning rate: 0.0160.. Train loss: 2.2599.. Train acc: 0.5245.. Val loss: 1.5280.. Val acc: 0.6289\n",
            "Epoch 186/300.. Learning rate: 0.0158.. Train loss: 2.2467.. Train acc: 0.5275.. Val loss: 1.5140.. Val acc: 0.6279\n",
            "Epoch 187/300.. Learning rate: 0.0156.. Train loss: 2.1558.. Train acc: 0.5470.. Val loss: 1.4338.. Val acc: 0.6328\n",
            "Epoch 188/300.. Learning rate: 0.0153.. Train loss: 2.1709.. Train acc: 0.5460.. Val loss: 1.5363.. Val acc: 0.6198\n",
            "Epoch 189/300.. Learning rate: 0.0151.. Train loss: 2.2636.. Train acc: 0.5222.. Val loss: 1.4922.. Val acc: 0.6302\n",
            "Epoch 190/300.. Learning rate: 0.0148.. Train loss: 2.1870.. Train acc: 0.5420.. Val loss: 1.4014.. Val acc: 0.6464\n",
            "Epoch 191/300.. Learning rate: 0.0146.. Train loss: 2.2723.. Train acc: 0.5215.. Val loss: 1.4458.. Val acc: 0.6448\n",
            "Epoch 192/300.. Learning rate: 0.0144.. Train loss: 2.1580.. Train acc: 0.5448.. Val loss: 1.4395.. Val acc: 0.6443\n",
            "Epoch 193/300.. Learning rate: 0.0141.. Train loss: 2.2149.. Train acc: 0.5346.. Val loss: 1.4217.. Val acc: 0.6379\n",
            "Epoch 194/300.. Learning rate: 0.0139.. Train loss: 2.1573.. Train acc: 0.5491.. Val loss: 1.4299.. Val acc: 0.6428\n",
            "Epoch 195/300.. Learning rate: 0.0137.. Train loss: 2.2121.. Train acc: 0.5404.. Val loss: 1.4399.. Val acc: 0.6482\n",
            "Epoch 196/300.. Learning rate: 0.0134.. Train loss: 2.1296.. Train acc: 0.5554.. Val loss: 1.4245.. Val acc: 0.6488\n",
            "Epoch 197/300.. Learning rate: 0.0132.. Train loss: 2.2596.. Train acc: 0.5280.. Val loss: 1.4696.. Val acc: 0.6399\n",
            "Epoch 198/300.. Learning rate: 0.0130.. Train loss: 2.1421.. Train acc: 0.5521.. Val loss: 1.4073.. Val acc: 0.6516\n",
            "Epoch 199/300.. Learning rate: 0.0127.. Train loss: 2.2065.. Train acc: 0.5407.. Val loss: 1.4750.. Val acc: 0.6389\n",
            "Epoch 200/300.. Learning rate: 0.0125.. Train loss: 2.2332.. Train acc: 0.5336.. Val loss: 1.5099.. Val acc: 0.6334\n",
            "Epoch 201/300.. Learning rate: 0.0123.. Train loss: 2.2071.. Train acc: 0.5368.. Val loss: 1.4111.. Val acc: 0.6491\n",
            "Epoch 202/300.. Learning rate: 0.0121.. Train loss: 2.1268.. Train acc: 0.5604.. Val loss: 1.4265.. Val acc: 0.6526\n",
            "Epoch 203/300.. Learning rate: 0.0118.. Train loss: 2.0717.. Train acc: 0.5778.. Val loss: 1.4488.. Val acc: 0.6434\n",
            "Epoch 204/300.. Learning rate: 0.0116.. Train loss: 2.0784.. Train acc: 0.5725.. Val loss: 1.3725.. Val acc: 0.6529\n",
            "Epoch 205/300.. Learning rate: 0.0114.. Train loss: 2.1122.. Train acc: 0.5690.. Val loss: 1.4263.. Val acc: 0.6475\n",
            "Epoch 206/300.. Learning rate: 0.0112.. Train loss: 2.1186.. Train acc: 0.5643.. Val loss: 1.4228.. Val acc: 0.6516\n",
            "Epoch 207/300.. Learning rate: 0.0110.. Train loss: 2.0690.. Train acc: 0.5770.. Val loss: 1.4430.. Val acc: 0.6410\n",
            "Epoch 208/300.. Learning rate: 0.0107.. Train loss: 2.1143.. Train acc: 0.5614.. Val loss: 1.3994.. Val acc: 0.6538\n",
            "Epoch 209/300.. Learning rate: 0.0105.. Train loss: 2.1038.. Train acc: 0.5675.. Val loss: 1.5224.. Val acc: 0.6317\n",
            "Epoch 210/300.. Learning rate: 0.0103.. Train loss: 2.0776.. Train acc: 0.5700.. Val loss: 1.4396.. Val acc: 0.6528\n",
            "Epoch 211/300.. Learning rate: 0.0101.. Train loss: 2.0775.. Train acc: 0.5742.. Val loss: 1.4382.. Val acc: 0.6470\n",
            "Epoch 212/300.. Learning rate: 0.0099.. Train loss: 2.0633.. Train acc: 0.5741.. Val loss: 1.3614.. Val acc: 0.6598\n",
            "Epoch 213/300.. Learning rate: 0.0097.. Train loss: 2.0658.. Train acc: 0.5751.. Val loss: 1.4062.. Val acc: 0.6574\n",
            "Epoch 214/300.. Learning rate: 0.0095.. Train loss: 2.0991.. Train acc: 0.5738.. Val loss: 1.3668.. Val acc: 0.6649\n",
            "Epoch 215/300.. Learning rate: 0.0093.. Train loss: 2.0340.. Train acc: 0.5849.. Val loss: 1.4260.. Val acc: 0.6596\n",
            "Epoch 216/300.. Learning rate: 0.0091.. Train loss: 2.0809.. Train acc: 0.5774.. Val loss: 1.3489.. Val acc: 0.6660\n",
            "Epoch 217/300.. Learning rate: 0.0089.. Train loss: 2.0783.. Train acc: 0.5772.. Val loss: 1.4015.. Val acc: 0.6594\n",
            "Epoch 218/300.. Learning rate: 0.0087.. Train loss: 2.0679.. Train acc: 0.5799.. Val loss: 1.3680.. Val acc: 0.6619\n",
            "Epoch 219/300.. Learning rate: 0.0085.. Train loss: 2.1176.. Train acc: 0.5678.. Val loss: 1.3664.. Val acc: 0.6623\n",
            "Epoch 220/300.. Learning rate: 0.0083.. Train loss: 1.9993.. Train acc: 0.6001.. Val loss: 1.4153.. Val acc: 0.6584\n",
            "Epoch 221/300.. Learning rate: 0.0081.. Train loss: 2.0274.. Train acc: 0.5928.. Val loss: 1.4177.. Val acc: 0.6633\n",
            "Epoch 222/300.. Learning rate: 0.0079.. Train loss: 2.0638.. Train acc: 0.5810.. Val loss: 1.3711.. Val acc: 0.6708\n",
            "Epoch 223/300.. Learning rate: 0.0077.. Train loss: 2.0321.. Train acc: 0.5916.. Val loss: 1.3926.. Val acc: 0.6668\n",
            "Epoch 224/300.. Learning rate: 0.0075.. Train loss: 2.0193.. Train acc: 0.5882.. Val loss: 1.3586.. Val acc: 0.6676\n",
            "Epoch 225/300.. Learning rate: 0.0073.. Train loss: 1.9996.. Train acc: 0.5970.. Val loss: 1.2967.. Val acc: 0.6826\n",
            "Epoch 226/300.. Learning rate: 0.0071.. Train loss: 2.0574.. Train acc: 0.5876.. Val loss: 1.3550.. Val acc: 0.6724\n",
            "Epoch 227/300.. Learning rate: 0.0070.. Train loss: 1.9853.. Train acc: 0.6009.. Val loss: 1.4361.. Val acc: 0.6636\n",
            "Epoch 228/300.. Learning rate: 0.0068.. Train loss: 2.0311.. Train acc: 0.5888.. Val loss: 1.3327.. Val acc: 0.6754\n",
            "Epoch 229/300.. Learning rate: 0.0066.. Train loss: 2.0000.. Train acc: 0.5962.. Val loss: 1.2902.. Val acc: 0.6811\n",
            "Epoch 230/300.. Learning rate: 0.0064.. Train loss: 1.9445.. Train acc: 0.6135.. Val loss: 1.3975.. Val acc: 0.6621\n",
            "Epoch 231/300.. Learning rate: 0.0062.. Train loss: 1.8969.. Train acc: 0.6253.. Val loss: 1.3252.. Val acc: 0.6796\n",
            "Epoch 232/300.. Learning rate: 0.0061.. Train loss: 1.8955.. Train acc: 0.6271.. Val loss: 1.3631.. Val acc: 0.6723\n",
            "Epoch 233/300.. Learning rate: 0.0059.. Train loss: 1.9701.. Train acc: 0.6077.. Val loss: 1.4216.. Val acc: 0.6684\n",
            "Epoch 234/300.. Learning rate: 0.0057.. Train loss: 1.8947.. Train acc: 0.6282.. Val loss: 1.3443.. Val acc: 0.6776\n",
            "Epoch 235/300.. Learning rate: 0.0056.. Train loss: 1.9893.. Train acc: 0.6016.. Val loss: 1.3332.. Val acc: 0.6787\n",
            "Epoch 236/300.. Learning rate: 0.0054.. Train loss: 1.9081.. Train acc: 0.6263.. Val loss: 1.3262.. Val acc: 0.6737\n",
            "Epoch 237/300.. Learning rate: 0.0052.. Train loss: 2.0340.. Train acc: 0.5912.. Val loss: 1.3347.. Val acc: 0.6789\n",
            "Epoch 238/300.. Learning rate: 0.0051.. Train loss: 1.9228.. Train acc: 0.6255.. Val loss: 1.4032.. Val acc: 0.6700\n",
            "Epoch 239/300.. Learning rate: 0.0049.. Train loss: 1.9576.. Train acc: 0.6095.. Val loss: 1.4157.. Val acc: 0.6716\n",
            "Epoch 240/300.. Learning rate: 0.0048.. Train loss: 1.8530.. Train acc: 0.6384.. Val loss: 1.3525.. Val acc: 0.6783\n",
            "Epoch 241/300.. Learning rate: 0.0046.. Train loss: 1.9568.. Train acc: 0.6174.. Val loss: 1.3617.. Val acc: 0.6802\n",
            "Epoch 242/300.. Learning rate: 0.0045.. Train loss: 1.8107.. Train acc: 0.6528.. Val loss: 1.2968.. Val acc: 0.6894\n",
            "Epoch 243/300.. Learning rate: 0.0043.. Train loss: 1.8678.. Train acc: 0.6392.. Val loss: 1.2963.. Val acc: 0.6917\n",
            "Epoch 244/300.. Learning rate: 0.0042.. Train loss: 1.9727.. Train acc: 0.6100.. Val loss: 1.3167.. Val acc: 0.6835\n",
            "Epoch 245/300.. Learning rate: 0.0040.. Train loss: 1.9008.. Train acc: 0.6267.. Val loss: 1.2647.. Val acc: 0.6969\n",
            "Epoch 246/300.. Learning rate: 0.0039.. Train loss: 1.8752.. Train acc: 0.6365.. Val loss: 1.3286.. Val acc: 0.6869\n",
            "Epoch 247/300.. Learning rate: 0.0038.. Train loss: 1.9116.. Train acc: 0.6292.. Val loss: 1.3439.. Val acc: 0.6823\n",
            "Epoch 248/300.. Learning rate: 0.0036.. Train loss: 1.7904.. Train acc: 0.6522.. Val loss: 1.2607.. Val acc: 0.6945\n",
            "Epoch 249/300.. Learning rate: 0.0035.. Train loss: 1.8341.. Train acc: 0.6453.. Val loss: 1.2384.. Val acc: 0.6951\n",
            "Epoch 250/300.. Learning rate: 0.0034.. Train loss: 1.9503.. Train acc: 0.6174.. Val loss: 1.3050.. Val acc: 0.6927\n",
            "Epoch 251/300.. Learning rate: 0.0032.. Train loss: 1.8946.. Train acc: 0.6304.. Val loss: 1.3161.. Val acc: 0.6899\n",
            "Epoch 252/300.. Learning rate: 0.0031.. Train loss: 1.8637.. Train acc: 0.6357.. Val loss: 1.3198.. Val acc: 0.6929\n",
            "Epoch 253/300.. Learning rate: 0.0030.. Train loss: 1.7881.. Train acc: 0.6590.. Val loss: 1.2834.. Val acc: 0.6963\n",
            "Epoch 254/300.. Learning rate: 0.0028.. Train loss: 1.7420.. Train acc: 0.6659.. Val loss: 1.2496.. Val acc: 0.7029\n",
            "Epoch 255/300.. Learning rate: 0.0027.. Train loss: 1.8182.. Train acc: 0.6518.. Val loss: 1.2805.. Val acc: 0.6995\n",
            "Epoch 256/300.. Learning rate: 0.0026.. Train loss: 1.8008.. Train acc: 0.6533.. Val loss: 1.3100.. Val acc: 0.6936\n",
            "Epoch 257/300.. Learning rate: 0.0025.. Train loss: 1.7873.. Train acc: 0.6569.. Val loss: 1.2854.. Val acc: 0.6970\n",
            "Epoch 258/300.. Learning rate: 0.0024.. Train loss: 1.8300.. Train acc: 0.6423.. Val loss: 1.3411.. Val acc: 0.6920\n",
            "Epoch 259/300.. Learning rate: 0.0023.. Train loss: 1.8649.. Train acc: 0.6392.. Val loss: 1.2851.. Val acc: 0.7037\n",
            "Epoch 260/300.. Learning rate: 0.0022.. Train loss: 1.8048.. Train acc: 0.6553.. Val loss: 1.2571.. Val acc: 0.7038\n",
            "Epoch 261/300.. Learning rate: 0.0021.. Train loss: 1.8760.. Train acc: 0.6319.. Val loss: 1.3095.. Val acc: 0.6942\n",
            "Epoch 262/300.. Learning rate: 0.0020.. Train loss: 1.7754.. Train acc: 0.6582.. Val loss: 1.2768.. Val acc: 0.6978\n",
            "Epoch 263/300.. Learning rate: 0.0019.. Train loss: 1.8180.. Train acc: 0.6487.. Val loss: 1.2962.. Val acc: 0.6971\n",
            "Epoch 264/300.. Learning rate: 0.0018.. Train loss: 1.8212.. Train acc: 0.6454.. Val loss: 1.2718.. Val acc: 0.7010\n",
            "Epoch 265/300.. Learning rate: 0.0017.. Train loss: 1.8344.. Train acc: 0.6491.. Val loss: 1.2619.. Val acc: 0.7027\n",
            "Epoch 266/300.. Learning rate: 0.0016.. Train loss: 1.8156.. Train acc: 0.6464.. Val loss: 1.2379.. Val acc: 0.7072\n",
            "Epoch 267/300.. Learning rate: 0.0015.. Train loss: 1.7628.. Train acc: 0.6640.. Val loss: 1.2208.. Val acc: 0.7076\n",
            "Epoch 268/300.. Learning rate: 0.0014.. Train loss: 1.7389.. Train acc: 0.6647.. Val loss: 1.2724.. Val acc: 0.7064\n",
            "Epoch 269/300.. Learning rate: 0.0013.. Train loss: 1.8021.. Train acc: 0.6514.. Val loss: 1.2722.. Val acc: 0.7036\n",
            "Epoch 270/300.. Learning rate: 0.0012.. Train loss: 1.7798.. Train acc: 0.6617.. Val loss: 1.2280.. Val acc: 0.7114\n",
            "Epoch 271/300.. Learning rate: 0.0011.. Train loss: 1.7654.. Train acc: 0.6667.. Val loss: 1.2896.. Val acc: 0.7038\n",
            "Epoch 272/300.. Learning rate: 0.0011.. Train loss: 1.7330.. Train acc: 0.6675.. Val loss: 1.2337.. Val acc: 0.7102\n",
            "Epoch 273/300.. Learning rate: 0.0010.. Train loss: 1.7615.. Train acc: 0.6641.. Val loss: 1.3136.. Val acc: 0.7012\n",
            "Epoch 274/300.. Learning rate: 0.0009.. Train loss: 1.7011.. Train acc: 0.6794.. Val loss: 1.2382.. Val acc: 0.7107\n",
            "Epoch 275/300.. Learning rate: 0.0009.. Train loss: 1.7448.. Train acc: 0.6678.. Val loss: 1.2816.. Val acc: 0.7031\n",
            "Epoch 276/300.. Learning rate: 0.0008.. Train loss: 1.8011.. Train acc: 0.6535.. Val loss: 1.2582.. Val acc: 0.7046\n",
            "Epoch 277/300.. Learning rate: 0.0007.. Train loss: 1.6814.. Train acc: 0.6848.. Val loss: 1.2100.. Val acc: 0.7120\n",
            "Epoch 278/300.. Learning rate: 0.0007.. Train loss: 1.7299.. Train acc: 0.6754.. Val loss: 1.2614.. Val acc: 0.7056\n",
            "Epoch 279/300.. Learning rate: 0.0006.. Train loss: 1.8102.. Train acc: 0.6487.. Val loss: 1.2495.. Val acc: 0.7093\n",
            "Epoch 280/300.. Learning rate: 0.0005.. Train loss: 1.7679.. Train acc: 0.6600.. Val loss: 1.2471.. Val acc: 0.7057\n",
            "Epoch 281/300.. Learning rate: 0.0005.. Train loss: 1.7519.. Train acc: 0.6676.. Val loss: 1.2387.. Val acc: 0.7102\n",
            "Epoch 282/300.. Learning rate: 0.0004.. Train loss: 1.7565.. Train acc: 0.6669.. Val loss: 1.2439.. Val acc: 0.7087\n",
            "Epoch 283/300.. Learning rate: 0.0004.. Train loss: 1.6920.. Train acc: 0.6818.. Val loss: 1.1926.. Val acc: 0.7156\n",
            "Epoch 284/300.. Learning rate: 0.0004.. Train loss: 1.6917.. Train acc: 0.6764.. Val loss: 1.1985.. Val acc: 0.7168\n",
            "Epoch 285/300.. Learning rate: 0.0003.. Train loss: 1.7103.. Train acc: 0.6732.. Val loss: 1.2695.. Val acc: 0.7066\n",
            "Epoch 286/300.. Learning rate: 0.0003.. Train loss: 1.7176.. Train acc: 0.6734.. Val loss: 1.1998.. Val acc: 0.7155\n",
            "Epoch 287/300.. Learning rate: 0.0002.. Train loss: 1.6189.. Train acc: 0.6987.. Val loss: 1.1981.. Val acc: 0.7146\n",
            "Epoch 288/300.. Learning rate: 0.0002.. Train loss: 1.7524.. Train acc: 0.6694.. Val loss: 1.2190.. Val acc: 0.7137\n",
            "Epoch 289/300.. Learning rate: 0.0002.. Train loss: 1.7470.. Train acc: 0.6685.. Val loss: 1.2323.. Val acc: 0.7108\n",
            "Epoch 290/300.. Learning rate: 0.0001.. Train loss: 1.7783.. Train acc: 0.6555.. Val loss: 1.2652.. Val acc: 0.7087\n",
            "Epoch 291/300.. Learning rate: 0.0001.. Train loss: 1.7540.. Train acc: 0.6631.. Val loss: 1.2521.. Val acc: 0.7097\n",
            "Epoch 292/300.. Learning rate: 0.0001.. Train loss: 1.7170.. Train acc: 0.6767.. Val loss: 1.2096.. Val acc: 0.7153\n",
            "Epoch 293/300.. Learning rate: 0.0001.. Train loss: 1.7181.. Train acc: 0.6727.. Val loss: 1.2346.. Val acc: 0.7102\n",
            "Epoch 294/300.. Learning rate: 0.0001.. Train loss: 1.7508.. Train acc: 0.6696.. Val loss: 1.2395.. Val acc: 0.7110\n",
            "Epoch 295/300.. Learning rate: 0.0000.. Train loss: 1.7909.. Train acc: 0.6573.. Val loss: 1.2651.. Val acc: 0.7096\n",
            "Epoch 296/300.. Learning rate: 0.0000.. Train loss: 1.6506.. Train acc: 0.6898.. Val loss: 1.1718.. Val acc: 0.7193\n",
            "Epoch 297/300.. Learning rate: 0.0000.. Train loss: 1.6816.. Train acc: 0.6813.. Val loss: 1.2077.. Val acc: 0.7149\n",
            "Epoch 298/300.. Learning rate: 0.0000.. Train loss: 1.7972.. Train acc: 0.6537.. Val loss: 1.3141.. Val acc: 0.7009\n",
            "Epoch 299/300.. Learning rate: 0.0000.. Train loss: 1.7109.. Train acc: 0.6788.. Val loss: 1.2328.. Val acc: 0.7093\n",
            "Epoch 300/300.. Learning rate: 0.0000.. Train loss: 1.7029.. Train acc: 0.6730.. Val loss: 1.1882.. Val acc: 0.7166\n",
            "Test loss:  1.2052703619003295\n",
            "Test acc:  0.7115\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Aq2z9qCqm6gV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}